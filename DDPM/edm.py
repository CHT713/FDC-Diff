import time

import torch
import torch.nn.functional as F
import numpy as np
import math
from torch import nn


from model import function


from model.noise import GammaNetwork, PredefinedNoiseSchedule
from typing import Union



class EDM(torch.nn.Module):
    def __init__(
            self,
            dynamics_scaffold, dynamics_rgroup,
            in_node_nf: int,
            n_dims: int,
            timesteps: int = 1000,
            noise_schedule='learned',
            noise_precision=1e-4,
            loss_type='vlb',
            norm_values=(1., 1., 1.),
            norm_biases=(None, 0., 0.),

    ):
        super().__init__()
        if noise_schedule == 'learned':
            assert loss_type == 'vlb', 'A noise schedule can only be learned with a vlb objective'
            self.gamma = GammaNetwork()
        else:  # ä½¿ç”¨ PredefinedNoiseSchedule æ ¹æ®æŒ‡å®šçš„è°ƒåº¦ç±»åž‹å’Œæ—¶é—´æ­¥é•¿é¢„å®šä¹‰å™ªå£°ã€‚
            # self.gamma = PredefinedNoiseSchedule(noise_schedule, timesteps=timesteps, precision=noise_precision)
            self.gamma_scaffold =PredefinedNoiseSchedule(noise_schedule='polynomial_2', timesteps=timesteps,precision=1e-5,task_type='scaffold')
            self.gamma_rgroup = PredefinedNoiseSchedule(noise_schedule='polynomial_2', timesteps=timesteps,precision=1e-5,task_type='rgroup')

        self.dynamics_scaffold = dynamics_scaffold
        self.dynamics_rgroup = dynamics_rgroup

        self.in_node_nf = in_node_nf
        self.n_dims = n_dims
        self.T = timesteps
        self.norm_values = norm_values
        self.norm_biases = norm_biases


    def forward(self, x, h, node_mask, fragment_mask, remaining_mask, rgroup_mask, scaffold_mask,
            edge_mask, context=None,
              task_id =None,pocket_mask=None):
        """
        æ ¹æ®å½“å‰è®­ç»ƒé˜¶æ®µï¼Œè¿›è¡Œä¸åŒåŒºåŸŸçš„å™ªå£°åŠ å™ªï¼š
          - skeleton: ç”Ÿæˆéª¨æž¶ remain éƒ¨åˆ†ï¼ˆfragment ä¿æŒä¸å˜ï¼‰
          - rgroup: å¯¹ rgroup éƒ¨åˆ†åŠ å™ªï¼Œä¿æŒ scaffold ä¸å˜
          - joint: è”åˆè®­ç»ƒï¼Œé‡‡ç”¨ rgroup åˆ†æ”¯ï¼ˆæ¡ä»¶ä¸­èžåˆå£è¢‹ä¿¡æ¯ï¼‰
        # """

        if task_id == 0:
            dynamics = self.dynamics_scaffold
        elif task_id == 1:
            dynamics = self.dynamics_rgroup
        else:
            raise NotImplementedError("Unknown task_id")

        x, h = self.normalize(x, h)
        xh = torch.cat([x, h], dim=2)

        # 2. æ ¹æ®é˜¶æ®µé€‰æ‹©å¯¹åº”çš„æŽ©ç åŠæ¡ä»¶ä¿¡æ¯
        if task_id == 0:
            # éª¨æž¶é˜¶æ®µï¼šç›®æ ‡æ˜¯ç”Ÿæˆ remain éƒ¨åˆ†ï¼Œä¿ç•™ fragment éƒ¨åˆ†
            noise_mask = remaining_mask  # ä»…å¯¹ remain éƒ¨åˆ†åŠ å™ª
        elif task_id == 1:
            # RåŸºå›¢é˜¶æ®µï¼šç›®æ ‡æ˜¯ç”Ÿæˆ rgroup éƒ¨åˆ†ï¼Œä¿æŒ scaffold ä¸å˜
            noise_mask = rgroup_mask  # ä»…å¯¹ rgroup éƒ¨åˆ†åŠ å™ª
        else:
            raise NotImplementedError("Unknown training stage: %s" % self.training_stage)

        delta_log_px = self.delta_log_px(noise_mask).mean()

        # ç”Ÿæˆä¸€ä¸ªå½¢çŠ¶ä¸º (batch_size, 1) çš„å¼ é‡ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä»Ž [0, self.T] èŒƒå›´å†…éšæœºæŠ½å–çš„æ•´æ•°
        t_int = torch.randint(0, self.T + 1, size=(x.size(0), 1), device=x.device).float()
        s_int = t_int - 1

        # å°†ç¦»æ•£æ—¶é—´æ­¥ t_int å’Œ s_int å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´å†…ã€‚
        t = t_int / self.T
        s = s_int / self.T
        # åˆ›å»ºæŽ©ç ï¼Œæ ‡è®°å“ªäº›æ ·æœ¬çš„ t_int ä¸º 0ã€‚
        t_is_zero = (t_int == 0).float().squeeze()
        t_is_not_zero = 1 - t_is_zero

        # # 5. è®¡ç®—æ‰©æ•£å‚æ•° gamma, alpha, sigma                 self.gamma(t)å¾—åˆ°æ¯ä¸ªæ—¶é—´æ­¥çš„å™ªå£°è°ƒåº¦å‚æ•°  Î³-t
        # gamma_t = self.inflate_batch_array(self.gamma(t), x)  # å°†è¿”å›žçš„ Î³ å€¼æ‰©å±•åˆ°ä¸Žç›®æ ‡å¼ é‡ x çš„å½¢çŠ¶åŒ¹é…ï¼Œ
        # gamma_s = self.inflate_batch_array(self.gamma(s), x)
        # alpha_t = self.alpha(gamma_t, x)  # æ ¹æ® Î³ å€¼è®¡ç®—Î±
        # sigma_t = self.sigma(gamma_t, x)   # æ ¹æ® Î³ å€¼è®¡ç®— Ïƒ

        if task_id == 0:
            gamma_t = self.inflate_batch_array(self.gamma_scaffold(t), x)
            gamma_s = self.inflate_batch_array(self.gamma_scaffold(s), x)
        else:
            gamma_t = self.inflate_batch_array(self.gamma_rgroup(t), x)
            gamma_s = self.inflate_batch_array(self.gamma_rgroup(s), x)

        alpha_t = self.alpha(gamma_t, x)
        sigma_t = self.sigma(gamma_t, x)


        eps_t = self.sample_combined_position_feature_noise(n_samples=x.size(0), n_nodes=x.size(1), mask=noise_mask)


        # 7. ç”ŸæˆåŠ å™ªæ ·æœ¬ z_t
        z_t = alpha_t * xh + sigma_t * eps_t

        if task_id == 0:
            z_t = xh * fragment_mask + z_t * noise_mask + xh * pocket_mask
        else :
            z_t = xh * scaffold_mask + z_t * rgroup_mask + xh * pocket_mask

        eps_t_hat = dynamics.forward(
                xh=z_t, t=t, node_mask=node_mask, noise_mask=noise_mask, context=context, edge_mask=edge_mask,
                task_id=task_id
            )

        eps_t_hat = eps_t_hat * noise_mask

        error_t = self.sum_except_batch((eps_t - eps_t_hat) ** 2)
        normalization = (self.n_dims + self.in_node_nf) * self.numbers_of_nodes(noise_mask)
        l2_loss = (error_t / normalization).mean()


        kl_prior = self.kl_prior(x, noise_mask, task_id).mean()

        SNR_weight = (self.SNR(gamma_s - gamma_t) - 1).squeeze(1).squeeze(1)
        loss_term_t = self.T * 0.5 * SNR_weight * error_t
        loss_term_t = (loss_term_t * t_is_not_zero).sum() / (t_is_not_zero.sum() + 1e-8)
        noise_norm = torch.norm(eps_t_hat, dim=[1, 2])
        noise_t_val = (noise_norm * t_is_not_zero).sum() / (t_is_not_zero.sum() + 1e-8)

        if t_is_zero.sum() > 0:
            neg_log_constants = -self.log_constant_of_p_x_given_z0(x, noise_mask, task_id)
            loss_term_0 = -self.log_p_xh_given_z0_without_constants(h, z_t, gamma_t, eps_t, eps_t_hat, noise_mask)
            loss_term_0 = loss_term_0 + neg_log_constants
            loss_term_0 = (loss_term_0 * t_is_zero).sum() / (t_is_zero.sum() + 1e-8)
            noise_0 = (noise_norm * t_is_zero).sum() / (t_is_zero.sum() + 1e-8)
        else:
            loss_term_0 = 0.
            noise_0 = 0.

        return delta_log_px, kl_prior, loss_term_t, loss_term_0, l2_loss, noise_t_val, noise_0,z_t


    @torch.no_grad()
    def sample_scaf_chain(self, x, h, node_mask, fragment_mask, edge_mask, context, keep_frames=None,
                    rem_mask=None, pocket_mask=None,id=None,node_mask_1=None):
        print("å¼€å§‹é‡‡æ ·")
        n_samples = x.size(0)
        n_nodes = x.size(1)

        # Normalization and concatenation
        x, h, = self.normalize(x, h)
        xh = torch.cat([x, h], dim=2)

        fragment_mask  = fragment_mask
        rem_mask = rem_mask

        z = self.sample_combined_position_feature_noise(n_samples, n_nodes, mask=rem_mask)
        z = xh * fragment_mask + z * rem_mask+xh * pocket_mask

        if keep_frames is None:
            keep_frames = self.T
        else:
            assert keep_frames <= self.T
        chain = torch.zeros((keep_frames,) + z.size(), device=z.device)

        for s in reversed(range(0, self.T)):
            s_array = torch.full((n_samples, 1), fill_value=s, device=z.device)
            t_array = s_array + 1
            s_array = s_array / self.T
            t_array = t_array / self.T

            z = self.sample_p_zs_given_zt_only_scaf(
                s=s_array,
                t=t_array,
                z_t=z,
                node_mask=node_mask,
                fragment_mask=fragment_mask,
                rem_mask=rem_mask,
                pocket_mask=pocket_mask,
                edge_mask=edge_mask,
                context=context,
                id=id,
                node_mask_1=node_mask_1
            )
            write_index = (s * keep_frames) // self.T
            chain[write_index] = self.unnormalize_z(z)

        # Finally sample p(x, h | z_0)
        x, h = self.sample_p_xh_given_z0_only_scaf(
            z_0=z,
            node_mask=node_mask,
            fragment_mask=fragment_mask,
            rem_mask=rem_mask,
            pocket_mask=pocket_mask,
            edge_mask=edge_mask,
            context=context,
            id=id,
            node_mask_1=node_mask_1
        )
        chain[0] = torch.cat([x, h], dim=2)

        return chain

    def sample_p_zs_given_zt_only_scaf(self, s, t, z_t, node_mask, fragment_mask, rem_mask, pocket_mask=None,
                                       edge_mask=None, context=None, id=None,node_mask_1=None):
        """Samples from zs ~ p(zs | zt). Only used during sampling. Samples only rgroup features and coords"""
        gamma_s = self.gamma_scaffold(s)
        gamma_t = self.gamma_scaffold(t)


        # è®¡ç®—æ¡ä»¶æ ‡å‡†å™ªå£°å·®å’Œç¼©æ”¾å› å­
        sigma2_t_given_s, sigma_t_given_s, alpha_t_given_s = self.sigma_and_alpha_t_given_s(gamma_t, gamma_s, z_t)


        sigma_s = self.sigma(gamma_s, target_tensor=z_t)
        sigma_t = self.sigma(gamma_t, target_tensor=z_t)


        # ç¥žç»ç½‘ç»œé¢„æµ‹å™ªå£°ï¼Œä»…é’ˆå¯¹ rem éƒ¨åˆ†
        eps_hat = self.dynamics_scaffold.forward(
           xh=z_t,
            t=t,
            node_mask=node_mask,
            task_id=id,
            noise_mask=rem_mask,
            edge_mask=edge_mask,
           context=context
        )
        eps_hat = eps_hat * rem_mask


        # è®¡ç®— p(z_s | z_t) çš„å‡å€¼ mu
        mu = z_t / alpha_t_given_s - (sigma2_t_given_s / alpha_t_given_s / sigma_t) * eps_hat

        # è®¡ç®— p(z_s | z_t) çš„æ ‡å‡†å·® sigma
        sigma = sigma_t_given_s * sigma_s / sigma_t


        # æ ¹æ®å‚æ•°é‡‡æ · z_s
        z_s = self.sample_normal(mu, sigma, rem_mask)
        z_s = z_t * fragment_mask + z_s * rem_mask + z_t * pocket_mask


        return z_s



    def sample_p_xh_given_z0_only_scaf(self, z_0, node_mask, fragment_mask, rem_mask, pocket_mask=None, edge_mask=None,
                                       context=None, id=None, node_mask_1=None):
        """Samples x ~ p(x|z0). Samples only rgroup features and coords"""
        zeros = torch.zeros(size=(z_0.size(0), 1), device=z_0.device)
        gamma_0 = self.gamma_scaffold(zeros)

        #  torch.exp(-gamma)
        # è®¡ç®—æ ‡å‡†å·®
        sigma_x = self.SNR(-0.5 * gamma_0).unsqueeze(1)

        # ç¥žç»ç½‘ç»œé¢„æµ‹å™ªå£°ï¼Œä»…é’ˆå¯¹ rem éƒ¨åˆ†
        eps_hat= self.dynamics_scaffold.forward(
            t=zeros,
            xh=z_0,
            node_mask=node_mask,
            task_id=id,
            noise_mask=rem_mask,
            edge_mask=edge_mask,
            context=context
        )  # å½¢çŠ¶ [N_rem, feats_dim + pos_dim]
        eps_hat = eps_hat * rem_mask

        # è®¡ç®— x çš„å‡å€¼
        mu_x = self.compute_x_pred(eps_t=eps_hat, z_t=z_0, gamma_t=gamma_0)

        # é‡‡æ · xh
        xh = self.sample_normal(mu=mu_x, sigma=sigma_x, node_mask=rem_mask)

        xh = z_0 * fragment_mask + xh * rem_mask + z_0 * pocket_mask

        # åˆ†ç¦» x å’Œ h å¹¶åå½’ä¸€åŒ–
        x, h = xh[:, :, :self.n_dims], xh[:, :, self.n_dims:]
        x_new, h_new = self.unnormalize(x, h)
        x, h = x_new, h_new  # æ›´æ–° x å’Œ h

        # å°† h è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç 
        h = F.one_hot(torch.argmax(h, dim=2), self.in_node_nf).float()  # ç¡®ä¿è¾“å‡ºä¸ºæµ®ç‚¹åž‹å¼ é‡
        # ç¡®ä¿ node_mask çš„å½¢çŠ¶åŒ¹é…
        node_mask1 = node_mask.expand_as(h)  # [batch_size, num_atoms, self.in_node_nf]
        h = h * node_mask1  # åº”ç”¨æŽ©ç 


        return x, h

    @torch.no_grad()
    def sample_chain(self, x, h, node_mask, scaffold_mask, rgroup_mask,pocket_mask=None,edge_mask=None, context=None, keep_frames=None,id=None):
        n_samples = x.size(0)
        n_nodes = x.size(1)

        # Normalization and concatenation
        x, h, = self.normalize(x, h)
        xh = torch.cat([x, h], dim=2)

        # Initial rgroup sampling from N(0, I)
        z = self.sample_combined_position_feature_noise(n_samples, n_nodes, mask=rgroup_mask)


        z = xh * scaffold_mask + z * rgroup_mask +xh*pocket_mask


        if keep_frames is None:
            keep_frames = self.T
        else:
            assert keep_frames <= self.T
        chain = torch.zeros((keep_frames,) + z.size(), device=z.device)
        # è¿™é‡Œ range(0, self.T) ç”Ÿæˆä»Ž 0 åˆ° self.T - 1 çš„æ•´æ•°åºåˆ—ã€‚
        # reversed(...) ä½¿å¾—å¾ªçŽ¯ä»Žæœ€åŽä¸€æ­¥ï¼ˆself.T - 1ï¼‰å¼€å§‹ï¼Œåˆ°ç¬¬ 0 æ­¥ç»“æŸã€‚
        # Sample p(z_s | z_t)
        for s in reversed(range(0, self.T)):
            s_array = torch.full((n_samples, 1), fill_value=s,
                                 device=z.device)  # ä¸ºå½“å‰æ—¶é—´æ­¥ s åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º (n_samples, 1) çš„å¼ é‡ï¼Œæ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æ—¶é—´æ­¥éƒ½ä¸º sã€‚
            t_array = s_array + 1
            s_array = s_array / self.T
            t_array = t_array / self.T

            z = self.sample_p_zs_given_zt_only_rgroup(
                s=s_array,
                t=t_array,
                z_t=z,
                node_mask=node_mask,
                scaffold_mask=scaffold_mask,
                rgroup_mask=rgroup_mask,
                pocket_mask=pocket_mask,
                edge_mask=edge_mask,
                context=context,
                id=id
            )
            # æ ¹æ®  ð‘ è®¡ç®—ä¿å­˜çš„ç´¢å¼• write_indexï¼ˆè¿™é‡Œé€šè¿‡çº¿æ€§æ˜ å°„ï¼‰ï¼Œå¹¶å°†ç»è¿‡åŽ»å½’ä¸€åŒ–å¤„ç†åŽçš„  z å­˜å…¥ chainã€‚
            write_index = (s * keep_frames) // self.T
            chain[write_index] = self.unnormalize_z(z)

        # Finally sample p(x, h | z_0)
        x, h = self.sample_p_xh_given_z0_only_rgroup(
            z_0=z,
            node_mask=node_mask,
            scaffold_mask=scaffold_mask,
            rgroup_mask=rgroup_mask,
            pocket_mask=pocket_mask,
            edge_mask=edge_mask,
            context=context,
            id=id
        )
        chain[0] = torch.cat([x, h], dim=2)

        return chain

    # åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œæ ¹æ®å½“å‰çŠ¶æ€Ztè®¡ç®—å¹¶ä¸”é‡‡æ ·å‡ºä¸Šä¸€ä¸ªæ—¶é—´æ­¥Zsçš„çŠ¶æ€ï¼Œæ¡ä»¶åˆ†å¸ƒ
    def sample_p_zs_given_zt_only_rgroup(self, s, t, z_t, node_mask, scaffold_mask, rgroup_mask,  pocket_mask, edge_mask, context,id=None):
        """Samples from zs ~ p(zs | zt). Only used during sampling. Samples only rgroup features and coords"""
        gamma_s = self.gamma_rgroup(s)
        gamma_t = self.gamma_rgroup(t)

        # è¿™ä¸ªå‡½æ•°æ ¹æ® gamma_t å’Œ gamma_s ä»¥åŠZtè®¡ç®—æ¡ä»¶æ ‡å‡†å™ªå£°å·®å’Œç¼©æ”¾å› å­
        sigma2_t_given_s, sigma_t_given_s, alpha_t_given_s = self.sigma_and_alpha_t_given_s(gamma_t, gamma_s, z_t)
        sigma_s = self.sigma(gamma_s, target_tensor=z_t)
        sigma_t = self.sigma(gamma_t, target_tensor=z_t)

        # Neural net prediction.
        eps_hat = self.dynamics_rgroup.forward(
            xh=z_t,
            t=t,
            node_mask=node_mask,
            noise_mask=rgroup_mask,
            context=context,
            edge_mask=edge_mask,
            task_id=id
        )
        eps_hat = eps_hat * rgroup_mask

        # Compute mu for p(z_s | z_t)
        mu = z_t / alpha_t_given_s - (sigma2_t_given_s / alpha_t_given_s / sigma_t) * eps_hat

        # Compute sigma for p(z_s | z_t)
        sigma = sigma_t_given_s * sigma_s / sigma_t

        # Sample z_s given the parameters derived from zt
        z_s = self.sample_normal(mu, sigma, rgroup_mask)
        z_s = z_t * scaffold_mask + z_s * rgroup_mask+z_t * pocket_mask

        return z_s

    def sample_p_xh_given_z0_only_rgroup(self, z_0, node_mask, scaffold_mask, rgroup_mask,pocket_mask, edge_mask, context,id=None):
        """Samples x ~ p(x|z0). Samples only rgroup features and coords"""
        zeros = torch.zeros(size=(z_0.size(0), 1), device=z_0.device)
        gamma_0 = self.gamma_rgroup(zeros)

        # Computes sqrt(sigma_0^2 / alpha_0^2)
        sigma_x = self.SNR(-0.5 * gamma_0).unsqueeze(1)
        eps_hat = self.dynamics_rgroup.forward(
            t=zeros,
            xh=z_0,
            node_mask=node_mask,
           noise_mask=rgroup_mask,
            edge_mask=edge_mask,
            context=context,
            task_id=id

        )
        eps_hat = eps_hat * rgroup_mask

        mu_x = self.compute_x_pred(eps_t=eps_hat, z_t=z_0, gamma_t=gamma_0)
        xh = self.sample_normal(mu=mu_x, sigma=sigma_x, node_mask=rgroup_mask)
        xh = z_0 * scaffold_mask + xh * rgroup_mask +z_0 * pocket_mask

        x, h = xh[:, :, :self.n_dims], xh[:, :, self.n_dims:]
        x, h = self.unnormalize(x, h)
        h = F.one_hot(torch.argmax(h, dim=2), self.in_node_nf) * node_mask

        return x, h


    def compute_x_pred(self, eps_t, z_t, gamma_t):
        """Computes x_pred, i.e. the most likely prediction of x."""
        sigma_t = self.sigma(gamma_t, target_tensor=eps_t)
        alpha_t = self.alpha(gamma_t, target_tensor=eps_t)
        x_pred = 1. / alpha_t * (z_t - sigma_t * eps_t)
        return x_pred

    def kl_prior(self, xh, mask,task):
        """
        Computes the KL between q(z1 | x) and the prior p(z1) = Normal(0, 1).
        This is essentially a lot of work for something that is in practice negligible in the loss.
        However, you compute it so that you see it when you've made a mistake in your noise schedule.
        """
        # Compute the last alpha value, alpha_T
        # xhï¼šè¾“å…¥æ•°æ®å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, n_nodes, n_dims + in_node_nf)ï¼ŒåŒ…å«ä½ç½® (x) å’Œç‰¹å¾ (h) ä¸¤éƒ¨åˆ†ã€‚
        ones = torch.ones((xh.size(0), 1), device=xh.device)# å½¢çŠ¶ä¸º (batch_size, 1) çš„å…¨ä¸€å¼ é‡ï¼Œè¡¨ç¤ºå½’ä¸€åŒ–çš„æ—¶é—´æ­¥
        if task == 0:
            gamma=self.gamma_scaffold
        else:
            gamma=self.gamma_rgroup
        # self.gamma = PredefinedNoiseSchedule(noise_schedule, timesteps=timesteps, precision=noise_precision)
        gamma_T =gamma(ones)
        alpha_T = self.alpha(gamma_T, xh)

        # Compute means
        mu_T = alpha_T * xh
        mu_T_x, mu_T_h = mu_T[:, :, :self.n_dims], mu_T[:, :, self.n_dims:]

        # Compute standard deviations (only batch axis for x-part, inflated for h-part)
        sigma_T_x = self.sigma(gamma_T, mu_T_x).view(-1)  # Remove inflate, only keep batch dimension for x-part
        sigma_T_h = self.sigma(gamma_T, mu_T_h)

        # Compute KL for h-part
        zeros, ones = torch.zeros_like(mu_T_h), torch.ones_like(sigma_T_h)
        kl_distance_h = self.gaussian_kl(mu_T_h, sigma_T_h, zeros, ones)

        # Compute KL for x-part
        zeros, ones = torch.zeros_like(mu_T_x), torch.ones_like(sigma_T_x)
        d = self.dimensionality(mask)
        kl_distance_x = self.gaussian_kl_for_dimension(mu_T_x, sigma_T_x, zeros, ones, d=d)

        return kl_distance_x + kl_distance_h

    def log_constant_of_p_x_given_z0(self, x, mask,task_id):
        batch_size = x.size(0)
        degrees_of_freedom_x = self.dimensionality(mask)
        zeros = torch.zeros((batch_size, 1), device=x.device)
        if task_id == 0:
            gamma_x = self.gamma_scaffold
        else:
            gamma_x = self.gamma_rgroup
        gamma_0 = gamma_x(zeros)

        # Recall that sigma_x = sqrt(sigma_0^2 / alpha_0^2) = SNR(-0.5 gamma_0)
        log_sigma_x = 0.5 * gamma_0.view(batch_size)

        return degrees_of_freedom_x * (- log_sigma_x - 0.5 * np.log(2 * np.pi))

    def log_p_xh_given_z0_without_constants(self, h, z_0, gamma_0, eps, eps_hat, mask, epsilon=1e-10):
        # Discrete properties are predicted directly from z_0
        z_h = z_0[:, :, self.n_dims:]

        # Take only part over x
        eps_x = eps[:, :, :self.n_dims]
        eps_hat_x = eps_hat[:, :, :self.n_dims]

        # Compute sigma_0 and rescale to the integer scale of the data
        sigma_0 = self.sigma(gamma_0, target_tensor=z_0) * self.norm_values[1]

        # Computes the error for the distribution N(x | 1 / alpha_0 z_0 + sigma_0/alpha_0 eps_0, sigma_0 / alpha_0),
        # the weighting in the epsilon parametrization is exactly '1'
        log_p_x_given_z_without_constants = -0.5 * self.sum_except_batch((eps_x - eps_hat_x) ** 2)

        # Categorical features
        # Compute delta indicator masks
        h = h * self.norm_values[1] + self.norm_biases[1]
        estimated_h = z_h * self.norm_values[1] + self.norm_biases[1]

        # Centered h_cat around 1, since onehot encoded
        centered_h = estimated_h - 1

        # Compute integrals from 0.5 to 1.5 of the normal distribution
        # N(mean=centered_h_cat, stdev=sigma_0_cat)
        log_p_h_proportional = torch.log(
            self.cdf_standard_gaussian((centered_h + 0.5) / sigma_0) -
            self.cdf_standard_gaussian((centered_h - 0.5) / sigma_0) +
            epsilon
        )

        # Normalize the distribution over the categories
        log_Z = torch.logsumexp(log_p_h_proportional, dim=2, keepdim=True)
        log_probabilities = log_p_h_proportional - log_Z

        # Select the log_prob of the current category using the onehot representation
        log_p_h_given_z = self.sum_except_batch(log_probabilities * h * mask)

        # Combine log probabilities for x and h
        log_p_xh_given_z = log_p_x_given_z_without_constants + log_p_h_given_z

        return log_p_xh_given_z

    def sample_combined_position_feature_noise(self, n_samples, n_nodes, mask):
        # å…¶åŠŸèƒ½æ˜¯ä¸ºå›¾ä¸­èŠ‚ç‚¹çš„ä½ç½®ï¼ˆåæ ‡ï¼‰å’Œç‰¹å¾ç”Ÿæˆé«˜æ–¯å™ªå£°ï¼Œå¹¶ä¸”åªå¯¹æŽ©ç ï¼ˆmaskï¼‰æ ‡è®°çš„éƒ¨åˆ†ç”Ÿæˆå™ªå£°ã€‚
        z_x = function.sample_gaussian_with_mask(
            size=(n_samples, n_nodes, self.n_dims),
            device=mask.device,
            node_mask=mask
        )
        z_h = function.sample_gaussian_with_mask(
            size=(n_samples, n_nodes, self.in_node_nf),
            device=mask.device,
            node_mask=mask
        )
        z = torch.cat([z_x, z_h], dim=2)
        return z

    def sample_normal(self, mu, sigma, node_mask):
        """Samples from a Normal distribution."""
        eps = self.sample_combined_position_feature_noise(mu.size(0), mu.size(1), node_mask)
        return mu + sigma * eps

    def normalize(self, x, h):
        new_x = x / self.norm_values[0]
        new_h = (h.float() - self.norm_biases[1]) / self.norm_values[1]
        return new_x, new_h

    def unnormalize(self, x, h):
        new_x = x * self.norm_values[0]
        new_h = h * self.norm_values[1] + self.norm_biases[1]
        return new_x, new_h

    def unnormalize_z(self, z):
        assert z.size(2) == self.n_dims + self.in_node_nf
        x, h = z[:, :, :self.n_dims], z[:, :, self.n_dims:]
        x, h = self.unnormalize(x, h)
        return torch.cat([x, h], dim=2)

    def delta_log_px(self, mask):
        return -self.dimensionality(mask) * np.log(self.norm_values[0])

    def dimensionality(self, mask): # ç»“æžœæ˜¯  æœ‰æ•ˆèŠ‚ç‚¹æ•°ç›®ä¹˜ä»¥ç»´åº¦æ•°ã€‚
        return self.numbers_of_nodes(mask) * self.n_dims

    def sigma(self, gamma, target_tensor):
        """Computes sigma given gamma."""
        return self.inflate_batch_array(torch.sqrt(torch.sigmoid(gamma)), target_tensor)

    def alpha(self, gamma, target_tensor):
        """Computes alpha given gamma."""
        return self.inflate_batch_array(torch.sqrt(torch.sigmoid(-gamma)), target_tensor)

    def SNR(self, gamma):
        """Computes signal to noise ratio (alpha^2/sigma^2) given gamma."""
        return torch.exp(-gamma)

    def sigma_and_alpha_t_given_s_scaf(self, gamma_t: torch.Tensor, gamma_s: torch.Tensor, target_tensor: torch.Tensor,s):
        """
        Computes sigma t given s, using gamma_t and gamma_s. Used during sampling.

        Added value clamping to prevent numerical instability and control variance growth.
        """
        # é™åˆ¶ gamma çš„èŒƒå›´ä»¥é˜²æ­¢æ•°å€¼ä¸ç¨³å®š
        gamma_t = gamma_t.clamp(min=-10., max=10.)
        gamma_s = gamma_s.clamp(min=-10., max=10.)

        # è®¡ç®— log(alpha_t^2) å’Œ log(alpha_s^2)
        log_alpha2_t = F.logsigmoid(-gamma_t)  # shape: (batch,)
        log_alpha2_s = F.logsigmoid(-gamma_s)  # shape: (batch,)

        # è®¡ç®— log((alpha_t/alpha_s)^2)
        log_alpha2_t_given_s = log_alpha2_t - log_alpha2_s  # shape: (batch,)

        # è®¡ç®— (alpha_t/alpha_s)^2 å¹¶æ·»åŠ çº¦æŸ
        alpha2_t_given_s = torch.exp(log_alpha2_t_given_s)  # (alpha_t/alpha_s)^2
        alpha2_t_given_s = torch.clamp(alpha2_t_given_s, min=1e-6, max=1.0)  # é˜²æ­¢å€¼è¿‡å°æˆ–å¤§äºŽ1

        # è®¡ç®— sigma^2 = 1 - alpha^2 å¹¶æ·»åŠ ä¸‹é™
        sigma2_t_given_s = 1.0 - alpha2_t_given_s
        sigma2_t_given_s = torch.clamp(sigma2_t_given_s, min=1e-10)  # é˜²æ­¢è´Ÿæ•°æˆ–è¿‡å°å€¼

        # æ‰©å±•åˆ°ç›®æ ‡å¼ é‡å½¢çŠ¶
        sigma2_t_given_s = self.inflate_batch_array(sigma2_t_given_s, target_tensor)
        alpha_t_given_s = torch.sqrt(self.inflate_batch_array(alpha2_t_given_s, target_tensor))
        sigma_t_given_s = torch.sqrt(sigma2_t_given_s)


        max_sigma = 1.0 * (s / self.T) if hasattr(self, 'T') else 1.0  # åŠ¨æ€æˆ–å›ºå®š
        sigma_t_given_s = torch.clamp(sigma_t_given_s, max=max_sigma)

        return sigma2_t_given_s, sigma_t_given_s, alpha_t_given_s

    def sigma_and_alpha_t_given_s(self, gamma_t: torch.Tensor, gamma_s: torch.Tensor, target_tensor: torch.Tensor):
        """
        Computes sigma t given s, using gamma_t and gamma_s. Used during sampling.

        These are defined as:
          alpha t given s = alpha t / alpha s,
          sigma t given s = sqrt(1 - (alpha t given s) ^2 ).
        """
        sigma2_t_given_s = self.inflate_batch_array(
            -self.expm1(self.softplus(gamma_s) - self.softplus(gamma_t)),
            target_tensor
        )

        # alpha_t_given_s = alpha_t / alpha_s
        log_alpha2_t = F.logsigmoid(-gamma_t)
        log_alpha2_s = F.logsigmoid(-gamma_s)
        log_alpha2_t_given_s = log_alpha2_t - log_alpha2_s

        alpha_t_given_s = torch.exp(0.5 * log_alpha2_t_given_s)
        alpha_t_given_s = self.inflate_batch_array(alpha_t_given_s, target_tensor)
        sigma_t_given_s = torch.sqrt(sigma2_t_given_s)

        return sigma2_t_given_s, sigma_t_given_s, alpha_t_given_s

    @staticmethod
    def numbers_of_nodes(mask):
        if mask.dim() == 3:
            mask = mask.squeeze(2)  # (B, N, 1) -> (B, N)
        elif mask.dim() != 2:
            raise ValueError(f"Unexpected mask shape: {mask.shape}")
        return torch.sum(mask, dim=1)  # (B, N) -> (B,)

    @staticmethod
    def inflate_batch_array(array, target):
        # å‡½æ•°çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ªæ‰¹æ¬¡çš„å¼ é‡ array æ‰©å±•åˆ°ä¸Žç›®æ ‡å½¢çŠ¶ target åŒ¹é…çš„å½¢çŠ¶ï¼Œæ‰©å±•çš„éƒ¨åˆ†æ˜¯ç»´åº¦ä¸º 1 çš„ç©ºç»´åº¦
        """
        Inflates the batch array (array) with only a single axis (i.e. shape = (batch_size,),
        or possibly more empty axes (i.e. shape (batch_size, 1, ..., 1)) to match the target shape.
        """
        target_shape = (array.size(0),) + (1,) * (len(target.size()) - 1)
        return array.view(target_shape)

    @staticmethod
    def sum_except_batch(x):
        return x.view(x.size(0), -1).sum(-1)

    @staticmethod
    def expm1(x: torch.Tensor) -> torch.Tensor:
        return torch.expm1(x)

    @staticmethod
    def softplus(x: torch.Tensor) -> torch.Tensor:
        return F.softplus(x)

    @staticmethod
    def cdf_standard_gaussian(x):
        return 0.5 * (1. + torch.erf(x / math.sqrt(2)))

    @staticmethod
    def gaussian_kl(q_mu, q_sigma, p_mu, p_sigma):
        """
        Computes the KL distance between two normal distributions.
        Args:
            q_mu: Mean of distribution q.
            q_sigma: Standard deviation of distribution q.
            p_mu: Mean of distribution p.
            p_sigma: Standard deviation of distribution p.
        Returns:
            The KL distance, summed over all dimensions except the batch dim.
        """
        kl = torch.log(p_sigma / q_sigma) + 0.5 * (q_sigma ** 2 + (q_mu - p_mu) ** 2) / (p_sigma ** 2) - 0.5
        return EDM.sum_except_batch(kl)

    @staticmethod
    def gaussian_kl_for_dimension(q_mu, q_sigma, p_mu, p_sigma, d):
        """
        Computes the KL distance between two normal distributions taking the dimension into account.
        Args:
            q_mu: Mean of distribution q.
            q_sigma: Standard deviation of distribution q.
            p_mu: Mean of distribution p.
            p_sigma: Standard deviation of distribution p.
            d: dimension
        Returns:
            The KL distance, summed over all dimensions except the batch dim.
        """
        mu_norm_2 = EDM.sum_except_batch((q_mu - p_mu) ** 2)
        return d * torch.log(p_sigma / q_sigma) + 0.5 * (d * q_sigma ** 2 + mu_norm_2) / (p_sigma ** 2) - 0.5 * d